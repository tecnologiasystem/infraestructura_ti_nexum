from __future__ import annotations

import atexit
import os
import pickle
import sys
from collections import deque
from collections.abc import Callable
from textwrap import dedent
from typing import Any, Final, TypeVar

from . import current_time, to_thread
from ._core._exceptions import BrokenWorkerIntepreter
from ._core._synchronization import CapacityLimiter
from .lowlevel import RunVar

if sys.version_info >= (3, 11):
    from typing import TypeVarTuple, Unpack
else:
    from typing_extensions import TypeVarTuple, Unpack

"""Constantes para formatos y configuración interna"""
UNBOUND: Final = 2  # Valor interno usado para control de cola (sin documentación clara)
FMT_UNPICKLED: Final = 0  # Formato de datos sin serializar con pickle
FMT_PICKLED: Final = 1  # Formato de datos serializados con pickle
DEFAULT_CPU_COUNT: Final = 8  # Número por defecto de CPUs para limitar concurrencia si no se detecta otro
MAX_WORKER_IDLE_TIME = 30  # Segundos que un worker puede estar inactivo antes de ser destruido

"""Variables genéricas para tipado"""
T_Retval = TypeVar("T_Retval")  # Tipo genérico para retorno de funciones
PosArgsT = TypeVarTuple("PosArgsT")  # Tipo genérico para tupla de argumentos posicionales

"""RunVar: Variables de contexto ligadas al event loop para manejar estado compartido"""
_idle_workers = RunVar[deque["Worker"]]("_available_workers")  
# Cola de workers disponibles para reutilizar sin crear nuevos

_default_interpreter_limiter = RunVar[CapacityLimiter]("_default_interpreter_limiter")
# Controla cuántos subintérpretes pueden ejecutarse simultáneamente


class Worker:
    """
    Representa un subintérprete Python aislado para ejecutar funciones en paralelo.

    Usa colas internas para enviar y recibir funciones y resultados entre el intérprete
    principal y el subintérprete.
    """

    """Código Python que se ejecuta dentro del subintérprete para procesar tareas"""
    _run_func = compile(
        dedent("""
        import _interpqueues as queues
        import _interpreters as interpreters
        from pickle import loads, dumps, HIGHEST_PROTOCOL

        item = queues.get(queue_id)[0]  # Extrae la tarea serializada de la cola
        try:
            func, args = loads(item)  # Deserializa la función y sus argumentos
            retval = func(*args)  # Ejecuta la función con sus argumentos
        except BaseException as exc:
            is_exception = True  # Marca que hubo una excepción
            retval = exc  # Guarda la excepción para devolverla
        else:
            is_exception = False  # No hubo excepción

        try:
            # Intenta enviar resultado sin serializar
            queues.put(queue_id, (retval, is_exception), FMT_UNPICKLED, UNBOUND)
        except interpreters.NotShareableError:
            # Si no es compartible, serializa resultado con pickle y envía
            retval = dumps(retval, HIGHEST_PROTOCOL)
            queues.put(queue_id, (retval, is_exception), FMT_PICKLED, UNBOUND)
        """),
        "<string>",
        "exec",
    )

    last_used: float = 0  # Marca temporal de última vez que se usó este worker

    _initialized: bool = False  # Estado de inicialización
    _interpreter_id: int  # ID del subintérprete
    _queue_id: int  # ID de la cola de mensajes

    def initialize(self) -> None:
        """
        Inicializa el subintérprete y su cola de comunicación.

        Crea el subintérprete y la cola, además configura variables globales en su
        espacio de nombres '__main__' necesarias para la comunicación.
        """
        import _interpqueues as queues
        import _interpreters as interpreters

        self._interpreter_id = interpreters.create()  # Crea un nuevo subintérprete
        self._queue_id = queues.create(2, FMT_UNPICKLED, UNBOUND)  # Crea cola para comunicación
        self._initialized = True  # Marca como inicializado

        # Asigna variables globales para que el subintérprete conozca su cola y formatos
        interpreters.set___main___attrs(
            self._interpreter_id,
            {
                "queue_id": self._queue_id,
                "FMT_PICKLED": FMT_PICKLED,
                "FMT_UNPICKLED": FMT_UNPICKLED,
                "UNBOUND": UNBOUND,
            },
        )

    def destroy(self) -> None:
        """
        Destruye el subintérprete y la cola asociada, liberando los recursos.
        """
        import _interpqueues as queues
        import _interpreters as interpreters

        if self._initialized:
            interpreters.destroy(self._interpreter_id)  # Destruye el subintérprete
            queues.destroy(self._queue_id)  # Destruye la cola asociada

    def _call(
        self,
        func: Callable[..., T_Retval],
        args: tuple[Any],
    ) -> tuple[Any, bool]:
        """
        Ejecuta la función con sus argumentos en el subintérprete.

        Serializa la función y argumentos, los envía a la cola del subintérprete,
        ejecuta el código interno que procesa la función y recupera el resultado o
        excepción desde la cola.
        
        :return: tupla (resultado, si hubo excepción)
        """
        import _interpqueues as queues
        import _interpreters as interpreters

        if not self._initialized:
            self.initialize()  # Inicializa si no estaba inicializado

        # Serializa función y argumentos para enviar al subintérprete
        payload = pickle.dumps((func, args), pickle.HIGHEST_PROTOCOL)
        queues.put(self._queue_id, payload, FMT_PICKLED, UNBOUND)  # Envía a la cola

        res: Any
        is_exception: bool
        # Ejecuta el código en el subintérprete para procesar la tarea
        if exc_info := interpreters.exec(self._interpreter_id, self._run_func):
            raise BrokenWorkerIntepreter(exc_info)  # Si falla, lanza excepción

        # Obtiene resultado y formato desde la cola
        (res, is_exception), fmt = queues.get(self._queue_id)[:2]
        if fmt == FMT_PICKLED:
            res = pickle.loads(res)  # Si está serializado, deserializa

        return res, is_exception

    async def call(
        self,
        func: Callable[..., T_Retval],
        args: tuple[Any],
        limiter: CapacityLimiter,
    ) -> T_Retval:
        """
        Ejecuta la función en el subintérprete de forma asíncrona.

        Utiliza un thread separado para no bloquear el event loop mientras el subintérprete
        procesa la tarea.

        Lanza la excepción si la función falla, o retorna el resultado.
        """
        result, is_exception = await to_thread.run_sync(
            self._call,
            func,
            args,
            limiter=limiter,
        )
        if is_exception:
            raise result  # Propaga excepción

        return result


def _stop_workers(workers: deque[Worker]) -> None:
    """
    Destruye todos los workers de la cola y limpia la lista.

    Esta función se usa en el registro atexit para liberar recursos al salir.
    """
    for worker in workers:
        worker.destroy()

    workers.clear()


async def run_sync(
    func: Callable[[Unpack[PosArgsT]], T_Retval],
    *args: Unpack[PosArgsT],
    limiter: CapacityLimiter | None = None,
) -> T_Retval:
    """
    Ejecuta una función con argumentos en un subintérprete Python gestionando
    concurrencia y reutilización de workers.

    - Verifica versión Python (>=3.13).
    - Obtiene o crea un worker libre.
    - Ejecuta la función en el worker.
    - Reutiliza o destruye workers inactivos para eficiencia.

    :param func: función a ejecutar en subintérprete
    :param args: argumentos posicionales para la función
    :param limiter: controla cantidad máxima de workers concurrentes
    :return: resultado devuelto por la función
    :raises BrokenWorkerIntepreter: en caso de error interno del subintérprete
    """
    if sys.version_info <= (3, 13):
        raise RuntimeError("subinterpreters require at least Python 3.13")

    if limiter is None:
        limiter = current_default_interpreter_limiter()  # Obtiene limitador por defecto

    try:
        idle_workers = _idle_workers.get()  # Obtiene workers libres actuales
    except LookupError:
        idle_workers = deque()
        _idle_workers.set(idle_workers)  # Inicializa si no existe
        atexit.register(_stop_workers, idle_workers)  # Registra limpieza al cerrar app

    async with limiter:  # Espera disponibilidad según limitador
        try:
            worker = idle_workers.pop()  # Reusa worker libre
        except IndexError:
            worker = Worker()  # Crea uno nuevo si no hay libres

    try:
        return await worker.call(func, args, limiter)  # Ejecuta la función en worker
    finally:
        now = current_time()
        # Limpia workers inactivos por más de MAX_WORKER_IDLE_TIME segundos
        while idle_workers:
            if now - idle_workers[0].last_used <= MAX_WORKER_IDLE_TIME:
                break

            await to_thread.run_sync(idle_workers.popleft().destroy, limiter=limiter)

        worker.last_used = current_time()
        idle_workers.append(worker)  # Vuelve a poner worker en cola libre


def current_default_interpreter_limiter() -> CapacityLimiter:
    """
    Devuelve el limitador usado por defecto para controlar cuantos subintérpretes se pueden ejecutar simultáneamente.

    Usa el número de CPUs del sistema o un valor por defecto si no se detecta.

    :return: objeto CapacityLimiter configurado para la concurrencia
    """
    try:
        return _default_interpreter_limiter.get()
    except LookupError:
        limiter = CapacityLimiter(os.cpu_count() or DEFAULT_CPU_COUNT)
        _default_interpreter_limiter.set(limiter)
        return limiter
