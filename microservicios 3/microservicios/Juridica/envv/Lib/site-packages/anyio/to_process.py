from __future__ import annotations

import os
import pickle
import subprocess
import sys
from collections import deque
from collections.abc import Callable
from importlib.util import module_from_spec, spec_from_file_location
from typing import TypeVar, cast

from ._core._eventloop import current_time, get_async_backend, get_cancelled_exc_class
from ._core._exceptions import BrokenWorkerProcess
from ._core._subprocesses import open_process
from ._core._synchronization import CapacityLimiter
from ._core._tasks import CancelScope, fail_after
from .abc import ByteReceiveStream, ByteSendStream, Process
from .lowlevel import RunVar, checkpoint_if_cancelled
from .streams.buffered import BufferedByteReceiveStream

if sys.version_info >= (3, 11):
    from typing import TypeVarTuple, Unpack
else:
    from typing_extensions import TypeVarTuple, Unpack

WORKER_MAX_IDLE_TIME = 300  # 5 minutos

T_Retval = TypeVar("T_Retval")
PosArgsT = TypeVarTuple("PosArgsT")

# Variables RunVar para manejo del estado del pool de procesos y concurrencia
_process_pool_workers: RunVar[set[Process]] = RunVar("_process_pool_workers")
_process_pool_idle_workers: RunVar[deque[tuple[Process, float]]] = RunVar("_process_pool_idle_workers")
_default_process_limiter: RunVar[CapacityLimiter] = RunVar("_default_process_limiter")


async def run_sync(
    func: Callable[[Unpack[PosArgsT]], T_Retval],
    *args: Unpack[PosArgsT],
    cancellable: bool = False,
    limiter: CapacityLimiter | None = None,
) -> T_Retval:
    """
    """
    """
    Ejecuta la función `func` con los argumentos `args` en un proceso worker separado.

    Esto permite aislar la ejecución para evitar que errores o bloqueos afecten
    el proceso principal.

    Parámetros:
    - func: función a ejecutar en el proceso worker.
    - args: argumentos posicionales para `func`.
    - cancellable: si es True, permite cancelar la tarea matando el worker.
    - limiter: opcional, limita la cantidad de procesos simultáneos.

    Retorna:
    - El resultado de la función `func` si se ejecuta correctamente.

    Comportamiento:
    - Reusa procesos workers libres o crea nuevos si no hay disponibles.
    - Mata procesos que llevan más de 5 minutos inactivos para liberar recursos.
    - Envia la función y argumentos serializados con pickle al proceso worker.
    - Recibe el resultado o excepción también serializados.
    - Maneja cancelación y errores con cuidado.
    """

    async def send_raw_command(pickled_cmd: bytes) -> object:
        """
        """
        """
        Envía un comando serializado (pickle) al proceso worker a través del pipe de stdin.

        Espera la respuesta que contiene el estado (RETURN o EXCEPTION) y la cantidad de bytes.

        Luego recibe la respuesta serializada (resultado o excepción).

        Si el worker falla o se cancela, elimina el worker de la lista y mata el proceso.

        Retorna:
        - El objeto deserializado devuelto por el worker (resultado o excepción).

        Lanza excepciones:
        - BrokenWorkerProcess si hay un error en la comunicación.
        - Propaga excepciones del worker recibidas serializadas.
        """
        try:
            await stdin.send(pickled_cmd)  # Envía la función y args serializados
            response = await buffered.receive_until(b"\n", 50)  # Espera status + tamaño
            status, length = response.split(b" ")
            if status not in (b"RETURN", b"EXCEPTION"):
                raise RuntimeError(
                    f"Worker process returned unexpected response: {response!r}"
                )

            pickled_response = await buffered.receive_exactly(int(length))  # Lee respuesta

        except BaseException as exc:
            workers.discard(process)  # Quita worker del pool activo
            try:
                process.kill()  # Mata proceso worker
                with CancelScope(shield=True):
                    await process.aclose()  # Cierra proceso async
            except ProcessLookupError:
                pass

            if isinstance(exc, get_cancelled_exc_class()):
                raise
            else:
                raise BrokenWorkerProcess from exc

        retval = pickle.loads(pickled_response)  # Deserializa resultado o excepción
        if status == b"EXCEPTION":
            assert isinstance(retval, BaseException)
            raise retval  # Si fue excepción, la propaga
        else:
            return retval  # Retorna resultado normal

    # Aquí empieza la lógica para obtener un proceso worker para ejecutar la función

    await checkpoint_if_cancelled()  # Punto de cancelación cooperativa

    request = pickle.dumps(("run", func, args), protocol=pickle.HIGHEST_PROTOCOL)
    """
    Serializa la instrucción para correr la función con sus argumentos,
    para enviarla al proceso worker.
    """

    try:
        workers = _process_pool_workers.get()
        idle_workers = _process_pool_idle_workers.get()
    except LookupError:
        workers = set()
        idle_workers = deque()
        _process_pool_workers.set(workers)
        _process_pool_idle_workers.set(idle_workers)
        get_async_backend().setup_process_pool_exit_at_shutdown(workers)
    """
    Obtiene o inicializa las estructuras que guardan:
    - workers activos (procesos)
    - workers inactivos (cola doblemente enlazada con timestamp de inactividad)
    """

    async with limiter or current_default_process_limiter():
        while idle_workers:
            process, idle_since = idle_workers.pop()
            if process.returncode is None:  # proceso aún está vivo
                stdin = cast(ByteSendStream, process.stdin)
                buffered = BufferedByteReceiveStream(
                    cast(ByteReceiveStream, process.stdout)
                )

                now = current_time()
                killed_processes: list[Process] = []

                # Mata procesos inactivos por más de 5 minutos para liberar recursos
                while idle_workers:
                    if now - idle_workers[0][1] < WORKER_MAX_IDLE_TIME:
                        break

                    process_to_kill, idle_since = idle_workers.popleft()
                    process_to_kill.kill()
                    workers.remove(process_to_kill)
                    killed_processes.append(process_to_kill)

                with CancelScope(shield=True):
                    for killed_process in killed_processes:
                        await killed_process.aclose()

                break  # Sal del ciclo, ya tenemos un proceso activo

            workers.remove(process)  # Proceso muerto, eliminar de pool

        else:
            """
            Si no hay procesos vivos en el pool, se crea uno nuevo:
            """
            command = [sys.executable, "-u", "-m", __name__]
            process = await open_process(
                command, stdin=subprocess.PIPE, stdout=subprocess.PIPE
            )
            try:
                stdin = cast(ByteSendStream, process.stdin)
                buffered = BufferedByteReceiveStream(
                    cast(ByteReceiveStream, process.stdout)
                )
                with fail_after(20):  # timeout 20 segundos para inicialización
                    message = await buffered.receive(6)

                if message != b"READY\n":
                    raise BrokenWorkerProcess(
                        f"Worker process returned unexpected response: {message!r}"
                    )

                main_module_path = getattr(sys.modules["__main__"], "__file__", None)
                pickled = pickle.dumps(
                    ("init", sys.path, main_module_path),
                    protocol=pickle.HIGHEST_PROTOCOL,
                )
                await send_raw_command(pickled)  # Inicializa worker con entorno
            except (BrokenWorkerProcess, get_cancelled_exc_class()):
                raise
            except BaseException as exc:
                process.kill()
                raise BrokenWorkerProcess(
                    "Error during worker process initialization"
                ) from exc

            workers.add(process)  # Añade worker nuevo al pool

        with CancelScope(shield=not cancellable):
            try:
                return cast(T_Retval, await send_raw_command(request))
            finally:
                if process in workers:
                    idle_workers.append((process, current_time()))


def current_default_process_limiter() -> CapacityLimiter:
    """
    """
    """
    Devuelve el limitador por defecto para la cantidad de procesos worker.

    Se basa en la cantidad de CPUs del sistema o 2 si no está disponible.

    Esto se usa para evitar saturar el sistema con demasiados procesos.
    """
    try:
        return _default_process_limiter.get()
    except LookupError:
        limiter = CapacityLimiter(os.cpu_count() or 2)
        _default_process_limiter.set(limiter)
        return limiter


def process_worker() -> None:
    """
    Esta función es el código que corre dentro de cada proceso worker.

    - Redirige stdin/stdout para que el código del usuario no interfiera con la comunicación padre-worker.
    - Envía "READY\n" para indicar que está listo.
    - Entra en loop infinito esperando comandos serializados:
      - Comando "init": inicializa sys.path y carga el módulo principal del proceso padre (pero como __mp_main__ para evitar recursión).
      - Comando "run": ejecuta la función con sus argumentos, capturando resultado o excepción.
    - Envía de vuelta el resultado serializado o la excepción.
    - Respeta señales de terminación para cerrar correctamente.
    """
    stdin = sys.stdin
    stdout = sys.stdout
    sys.stdin = open(os.devnull)
    sys.stdout = open(os.devnull, "w")

    stdout.buffer.write(b"READY\n")  # Indica al padre que está listo

    while True:
        retval = exception = None
        try:
            command, *args = pickle.load(stdin.buffer)  # Espera comando serializado
        except EOFError:
            return  # Padre cerró pipe, termina worker
        except BaseException as exc:
            exception = exc
        else:
            if command == "run":
                func, args = args
                try:
                    retval = func(*args)  # Ejecuta función
                except BaseException as exc:
                    exception = exc
            elif command == "init":
                sys.path, main_module_path = args
                del sys.modules["__main__"]  # Limpia módulo principal actual
                if main_module_path and os.path.isfile(main_module_path):
                    try:
                        spec = spec_from_file_location("__mp_main__", main_module_path)
                        if spec and spec.loader:
                            main = module_from_spec(spec)
                            spec.loader.exec_module(main)  # Carga módulo principal como __mp_main__
                            sys.modules["__main__"] = main
                    except BaseException as exc:
                        exception = exc

        try:
            if exception is not None:
                status = b"EXCEPTION"
                pickled = pickle.dumps(exception, pickle.HIGHEST_PROTOCOL)
            else:
                status = b"RETURN"
                pickled = pickle.dumps(retval, pickle.HIGHEST_PROTOCOL)
        except BaseException as exc:
            exception = exc
            status = b"EXCEPTION"
            pickled = pickle.dumps(exc, pickle.HIGHEST_PROTOCOL)

        stdout.buffer.write(b"%s %d\n" % (status, len(pickled)))  # Envía status y tamaño
        stdout.buffer.write(pickled)  # Envía resultado serializado

        if isinstance(exception, SystemExit):
            raise exception  # Termina worker si recibió SystemExit


if __name__ == "__main__":
    process_worker()  # Si se ejecuta como módulo, corre worker
